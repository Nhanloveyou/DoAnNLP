{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bản sao của Increase RAM Reference Notes By Techhawa .ipynb","provenance":[{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1624592813617}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tZRSiDYNQLSr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626713147930,"user_tz":-420,"elapsed":427,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"2da8b4c4-3593-441d-cdec-814d18e33a3d"},"source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA')\n","print('Kết nối đến thư mục code thành công')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Kết nối đến thư mục code thành công\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"87T5BetZQYQv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626713152739,"user_tz":-420,"elapsed":2899,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"b8593a1a-0025-453a-ab9a-4ae16449a05e"},"source":["!pip install elasticsearch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: elasticsearch in /usr/local/lib/python3.7/dist-packages (7.13.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2021.5.30)\n","Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YOckP_sYQcda","executionInfo":{"status":"ok","timestamp":1626713154572,"user_tz":-420,"elapsed":1840,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}}},"source":["import numpy\n","import sklearn\n","import termcolor\n","import regex\n","import tqdm\n","import prettytable\n","import scipy\n","import nltk\n","import elasticsearch\n","import spacy\n","# import pexpect==4.2.1"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQ5aQ387P548"},"source":["Nếu lỗi ô này, khởi động lại tgian chạy, trước đó phải mount để kết nối đến drive"]},{"cell_type":"code","metadata":{"id":"_F9FfyFSQl_5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626713175053,"user_tz":-420,"elapsed":20486,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"7079572f-77f1-4946-86d5-5ad5ee1b4561"},"source":["from drqa.tokenizers import SpacyTokenizer\n","tok = SpacyTokenizer()\n","tok.tokenize('hello world').words() # Should complete immediately"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', 'world']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"xalsFDNyQp66","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626441161650,"user_tz":-420,"elapsed":3813,"user":{"displayName":"Thien Vo Hong","photoUrl":"","userId":"13519670590537774981"}},"outputId":"e51c4c54-f2ed-4d62-ba8e-0d88c84255fc"},"source":["import drqa.reader\n","drqa.reader.set_default('model', '/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/reader/single.mdl')\n","reader = drqa.reader.Predictor() \n","print('Done')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["chạy xong\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XryjXIYhQ_gM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626714180502,"user_tz":-420,"elapsed":1005457,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"3f1b9547-e6d1-42d0-b6fa-4a8262d9d532"},"source":["! python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/interactive.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["07/19/2021 04:46:17 PM: [ Initializing ranker... ]\n","07/19/2021 04:46:17 PM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x561585eb4000 @  0x7f837d8d41e7 0x7f837977846e 0x7f83797c8c7b 0x7f837977bce8 0x56157fd36a65 0x56157fcf78a9 0x56157fd6bb0a 0x56157fd65c35 0x56157fcf873a 0x56157fd6793b 0x56157fcfa6db 0x56157fd3b439 0x56157fd3b3ac 0x56157fddf119 0x56157fd6707e 0x56157fcf865a 0x56157fd6af40 0x56157fd65c35 0x56157fcf8fec 0x56157fd39bc9 0x56157fd36ac4 0x56157fcf78a9 0x56157fd6bb0a 0x56157fd65c35 0x56157fd65933 0x56157fe2f402 0x56157fe2f77d 0x56157fe2f626 0x56157fe07313 0x56157fe06fbc 0x7f837c6bebf7\n","tcmalloc: large alloc 4253114368 bytes == 0x561781798000 @  0x7f837d8d41e7 0x7f837977846e 0x7f83797c8c7b 0x7f837977bce8 0x56157fd36a65 0x56157fcf78a9 0x56157fd6bb0a 0x56157fd65c35 0x56157fcf873a 0x56157fd6793b 0x56157fcfa6db 0x56157fd3b439 0x56157fd3b3ac 0x56157fddf119 0x56157fd6707e 0x56157fcf865a 0x56157fd6af40 0x56157fd65c35 0x56157fcf8fec 0x56157fd39bc9 0x56157fd36ac4 0x56157fcf78a9 0x56157fd6bb0a 0x56157fd65c35 0x56157fd65933 0x56157fe2f402 0x56157fe2f77d 0x56157fe2f626 0x56157fe07313 0x56157fe06fbc 0x7f837c6bebf7\n","\n","Interactive TF-IDF DrQA Retriever\n",">> process(question, k=1)\n",">> usage()\n","\n",">>> process(\"Who is the author of Doraemon manga?\", 6)\n","+------+-----------------------------------------------------+-----------+\n","| Rank |                        Doc Id                       | Doc Score |\n","+------+-----------------------------------------------------+-----------+\n","|  1   |                       Doraemon                      |   460.34  |\n","|  2   |                 Doraemon in Vietnam                 |   422.79  |\n","|  3   |             2112: The Birth of Doraemon             |   325.06  |\n","|  4   |                       Dōjinshi                      |   231.88  |\n","|  5   |                 Doraemon (character)                |   228.62  |\n","|  6   | Doraemon: Nobita's Great Battle of the Mermaid King |   227.83  |\n","+------+-----------------------------------------------------+-----------+\n",">>> process(\"Which team won the 2014 World Cup?\", 3)\n","+------+--------------------------------+-----------+\n","| Rank |             Doc Id             | Doc Score |\n","+------+--------------------------------+-----------+\n","|  1   | Belgium national football team |   190.15  |\n","|  2   | France national football team  |   188.37  |\n","|  3   | Germany national football team |   185.95  |\n","+------+--------------------------------+-----------+\n",">>> \n","KeyboardInterrupt\n",">>> \n","KeyboardInterrupt\n",">>> ^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WjCCU1UaKiVK"},"source":["phải sửa lại đường dẫn trong file interactive"]},{"cell_type":"code","metadata":{"id":"udzWIlR8FXNd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626714843118,"user_tz":-420,"elapsed":125568,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"72cb2edd-499c-4a45-b68a-4bc0b0740081"},"source":["! python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/reader/interactive.py --model /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/reader/single.mdl"],"execution_count":7,"outputs":[{"output_type":"stream","text":["07/19/2021 05:11:59 PM: [ Running on CPU only. ]\n","07/19/2021 05:11:59 PM: [ Initializing model... ]\n","07/19/2021 05:11:59 PM: [ Loading model /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/reader/single.mdl ]\n","07/19/2021 05:11:59 PM: [ Initializing tokenizer... ]\n","\n","DrQA Interactive Document Reader Module\n",">> process(document, question, candidates=None, top_n=1)\n",">> usage()\n","\n","in the 1956 World Series?')')\n","  File \"<console>\", line 1\n","    process('In 1954, the Yankees won over 100 games, but the Indians took the pennant with an AL record 111 wins; 1954 was famously referred to as \"The Year the Yankees Lost the Pennant\". In , the Dodgers finally beat the Yankees in the World Series, after five previous Series losses to them, but the Yankees came back strong the next year. On October 8, 1956, in Game Five of the 1956 World Series against the Dodgers, pitcher Don Larsen threw the only perfect game in World Series history, which remains the only perfect game in postseason play and was the only no-hitter of any kind to be pitched in postseason play until Roy Halladay pitched a no-hitter on October 6, 2010.', 'process('Who was the winning pitcher in the 1956 World Series?')')\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^\n","SyntaxError: invalid syntax\n","56 World Series?')\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","+------+------------+--------------------+\n","| Rank |    Span    |       Score        |\n","+------+------------+--------------------+\n","|  1   | Don Larsen | 0.9583509564399719 |\n","+------+------------+--------------------+\n","Time: 0.1002\n","mans in a natural language.', 'What is question answering?')\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","+------+----------------------------------------------------------------------------------------------------------+---------------------+\n","| Rank |                                                   Span                                                   |        Score        |\n","+------+----------------------------------------------------------------------------------------------------------+---------------------+\n","|  1   | a computer science discipline within the fields of information retrieval and natural language processing | 0.17957346141338348 |\n","+------+----------------------------------------------------------------------------------------------------------+---------------------+\n","Time: 0.0393\n",">>> Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/code.py\", line 227, in interact\n","    line = self.raw_input(prompt)\n","  File \"/usr/lib/python3.7/code.py\", line 274, in raw_input\n","    return input(prompt)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/reader/interactive.py\", line 86, in <module>\n","    code.interact(banner=banner, local=locals())\n","  File \"/usr/lib/python3.7/code.py\", line 301, in interact\n","    console.interact(banner, exitmsg)\n","  File \"/usr/lib/python3.7/code.py\", line 234, in interact\n","    self.write(\"\\nKeyboardInterrupt\\n\")\n","  File \"/usr/lib/python3.7/code.py\", line 159, in write\n","    sys.stderr.write(data)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UR93zJjZ-d6f"},"source":["Cài đặt java8 để chạy"]},{"cell_type":"code","metadata":{"id":"JRh4G-M5OMd9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1626726160736,"user_tz":-420,"elapsed":10782857,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"989bee9d-7388-463b-e8a9-233002c06090"},"source":["! python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/pipeline/interactive.py"],"execution_count":8,"outputs":[{"output_type":"stream","text":["07/19/2021 05:23:01 PM: [ Running on CPU only. ]\n","07/19/2021 05:23:01 PM: [ Initializing pipeline... ]\n","07/19/2021 05:23:01 PM: [ Initializing document ranker... ]\n","07/19/2021 05:23:01 PM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x560b16432000 @  0x7f162adeb1e7 0x7f15ceaee46e 0x7f15ceb3ec7b 0x7f15ceaf1ce8 0x560b10619a65 0x560b105da8a9 0x560b1064eb0a 0x560b10648c35 0x560b105db73a 0x560b1064a93b 0x560b105dd6db 0x560b1061e439 0x560b1061e3ac 0x560b106c2119 0x560b1064a07e 0x560b105db65a 0x560b1064df40 0x560b10648c35 0x560b105dbfec 0x560b1061cbc9 0x560b10619ac4 0x560b105dc1f1 0x560b1064b318 0x560b10648c35 0x560b105dbfec 0x560b1061cbc9 0x560b10619ac4 0x560b105da8a9 0x560b1064eb0a 0x560b10648c35 0x560b10648933\n","tcmalloc: large alloc 4253114368 bytes == 0x560d11d00000 @  0x7f162adeb1e7 0x7f15ceaee46e 0x7f15ceb3ec7b 0x7f15ceaf1ce8 0x560b10619a65 0x560b105da8a9 0x560b1064eb0a 0x560b10648c35 0x560b105db73a 0x560b1064a93b 0x560b105dd6db 0x560b1061e439 0x560b1061e3ac 0x560b106c2119 0x560b1064a07e 0x560b105db65a 0x560b1064df40 0x560b10648c35 0x560b105dbfec 0x560b1061cbc9 0x560b10619ac4 0x560b105dc1f1 0x560b1064b318 0x560b10648c35 0x560b105dbfec 0x560b1061cbc9 0x560b10619ac4 0x560b105da8a9 0x560b1064eb0a 0x560b10648c35 0x560b10648933\n","07/19/2021 05:29:11 PM: [ Initializing document reader... ]\n","07/19/2021 05:29:11 PM: [ Loading model /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/reader/multitask.mdl ]\n","07/19/2021 05:29:14 PM: [ Initializing tokenizers and document retrievers... ]\n","\n","Interactive DrQA\n",">> process(question, candidates=None, top_n=1, n_docs=5)\n",">> usage()\n","\n",">>> process(\"Which team won world cup 2014?\", n_doc=5)\n","Traceback (most recent call last):\n","  File \"<console>\", line 1, in <module>\n","TypeError: process() got an unexpected keyword argument 'n_doc'\n",">>> process(\"Which team won world cup 2014?\", 5)\n","07/19/2021 05:43:42 PM: [ Processing 1 queries... ]\n","07/19/2021 05:43:42 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:43:51 PM: [ Reading 220 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","multiprocessing.pool.RemoteTraceback: \n","\"\"\"\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/model.py\", line 371, in decode_candidates\n","    if span in cands or span.lower() in cands:\n","TypeError: argument of type 'int' is not iterable\n","\"\"\"\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"<console>\", line 1, in <module>\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/pipeline/interactive.py\", line 83, in process\n","    question, candidates, top_n, n_docs, return_context=True\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/pipeline/drqa.py\", line 190, in process\n","    top_n, n_docs, return_context\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/pipeline/drqa.py\", line 277, in process_batch\n","    s, e, score = result.get()\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n","    raise self._value\n","TypeError: argument of type 'int' is not iterable\n",">>> process(\"Which team won world cup 2014?\")\n","07/19/2021 05:44:20 PM: [ Processing 1 queries... ]\n","07/19/2021 05:44:20 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:44:20 PM: [ Reading 220 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","Process ForkPoolWorker-2:\n","Process ForkPoolWorker-1:\n","\n","KeyboardInterrupt\n",">>> Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","process(\"Which team won world cup 2014?\")\n","07/19/2021 05:44:54 PM: [ Processing 1 queries... ]\n","07/19/2021 05:44:54 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:44:54 PM: [ Reading 220 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 05:44:59 PM: [ Processed 1 queries in 4.8605 (s) ]\n","Top Predictions:\n","+------+----------------+---------------------+--------------+-----------+\n","| Rank |     Answer     |         Doc         | Answer Score | Doc Score |\n","+------+----------------+---------------------+--------------+-----------+\n","|  1   | Northern Pride | 2014 Queensland Cup |    123.62    |   257.74  |\n","+------+----------------+---------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = 2014 Queensland Cup ]\n","The competition, known as the Entrust Super Cup for sponsorship purposes was contested by thirteen teams over a 30-week-long season (including finals) which was eventually won by the \u001b[1m\u001b[32mNorthern Pride\u001b[0m, with the Cairns based club beating the Easts Tigers 36-4 in the 2014 Grand Final at Suncorp Stadium.\n","\n",">>> process(\"Which team won the 2014 world cup? \",5)\n","07/19/2021 05:46:08 PM: [ Processing 1 queries... ]\n","07/19/2021 05:46:08 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:46:31 PM: [ Reading 314 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","multiprocessing.pool.RemoteTraceback: \n","\"\"\"\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/model.py\", line 371, in decode_candidates\n","    if span in cands or span.lower() in cands:\n","TypeError: argument of type 'int' is not iterable\n","\"\"\"\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"<console>\", line 1, in <module>\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/pipeline/interactive.py\", line 83, in process\n","    question, candidates, top_n, n_docs, return_context=True\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/pipeline/drqa.py\", line 190, in process\n","    top_n, n_docs, return_context\n","  File \"/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/pipeline/drqa.py\", line 277, in process_batch\n","    s, e, score = result.get()\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n","    raise self._value\n","TypeError: argument of type 'int' is not iterable\n",">>> process(\"Which team won the 2014 world cup? \",n_docs=5)\n","07/19/2021 05:47:08 PM: [ Processing 1 queries... ]\n","07/19/2021 05:47:08 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:47:08 PM: [ Reading 314 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 05:47:12 PM: [ Processed 1 queries in 3.8234 (s) ]\n","Top Predictions:\n","+------+-------------+--------------------------------+--------------+-----------+\n","| Rank |    Answer   |              Doc               | Answer Score | Doc Score |\n","+------+-------------+--------------------------------+--------------+-----------+\n","|  1   | El Salvador | Belgium national football team |    1145.9    |   190.15  |\n","+------+-------------+--------------------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = Belgium national football team ]\n","Belgium failed to progress past the first round of their earliest five World Cup participations. After two scoreless defeats at the inaugural World Cup in 1930, the team scored in their first-round knockout games in the 1934 and 1938 editions—but only enough to save their honour. In 1954, they tied with England (4–4 after extra time), and in 1970, they won their first World Cup match, against \u001b[1m\u001b[32mEl Salvador\u001b[0m (3–0). From 1982 until 2002, Belgium reached six successive World Cups by playing qualification rounds, advancing to the second phase five times. In the 1982 FIFA World Cup opener, Belgium beat defending champions Argentina 1–0. Their tournament ended in the second group stage, after a Polish hat-trick by Zbigniew Boniek and a 0–1 loss against the Soviet Union.\n","\n",">>> process(\"Who is the author of Doraemon manga? \",top_n=5)\n","07/19/2021 05:49:32 PM: [ Processing 1 queries... ]\n","07/19/2021 05:49:32 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 05:49:41 PM: [ Reading 95 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 05:49:42 PM: [ Processed 1 queries in 9.7808 (s) ]\n","Top Predictions:\n","+------+------------------+----------------------+--------------+-----------+\n","| Rank |      Answer      |         Doc          | Answer Score | Doc Score |\n","+------+------------------+----------------------+--------------+-----------+\n","|  1   | Fujiko F. Fujio  |       Doraemon       |  1.0867e+05  |   460.34  |\n","|  2   | Timothy J. Craig | Doraemon (character) |    58554     |   228.62  |\n","|  3   | Fujiko F. Fujio  |       Dōjinshi       |    5568.2    |   231.88  |\n","|  4   | Hiroshi Fujimoto | Doraemon (character) |    2032.2    |   228.62  |\n","|  5   |   Osamu Tezuka   |       Doraemon       |    1466.8    |   460.34  |\n","+------+------------------+----------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = Doraemon ]\n","Doraemon () is a Japanese manga series written and illustrated by \u001b[1m\u001b[32mFujiko F. Fujio\u001b[0m. The series has also been adapted into a successful anime series and media franchise. The story revolves around a robotic cat named Doraemon, who travels back in time from the 22nd century to aid a pre-teen boy named .\n","\n","[ Doc = Doraemon (character) ]\n","In terms of popularity the character has been compared to Walt Disney's Mickey Mouse, and the character is considered to be an iconic figure in Japan. The character has received criticism in Chinese media outlets where they considered Doraemon to be a politically subversive character and that it was a tool of Japan's “cultural invasion\". In his book \"Japan Pop: Inside the World of Japanese Popular Culture\", author \u001b[1m\u001b[32mTimothy J. Craig\u001b[0m wrote that the character of Doraemon \"Though Doraemon is himself a high-tech product, he possesses an endearing personality that captivates young audiences. He is both a full member of Nobita's family and an intimate friend to Nobita and his companions. Portrayed in this way, Doraemon represents the optimistic view of the relationship between technology and humanity.\"\n","\n","[ Doc = Dōjinshi ]\n","There are two notable instances of legal action over dōjinshi. In 1999, the author of an erotic Pokémon manga was prosecuted by Nintendo. This created a media furor as well as an academic analysis in Japan of the copyright issues around dōjinshi. At this time, the legal analysis seemed to conclude that dōjinshi should be overlooked because they are produced by amateurs for one-day events and not sold in the commercial market. In 2006, an artist selling an imagined \"final chapter\" for the series \"Doraemon\", which was never completed, was given a warning by the estate of author \u001b[1m\u001b[32mFujiko F. Fujio\u001b[0m. His creation apparently looked confusingly similar to a real Doraemon manga. He ceased distribution of his dōjinshi and sent compensation to the publisher voluntarily. The publisher noted at this time that dōjinshi were not usually a cause of concern for him. The Yomiuri Shinbun noted, \"Fanzines don't usually cause many problems as long as they are sold only at one-day exhibitions,\" but quoted an expert saying that due to their increasing popularity a copyright system should be set up.\n","\n","[ Doc = Doraemon (character) ]\n","Doraemon was originally conceived by \u001b[1m\u001b[32mHiroshi Fujimoto\u001b[0m following a series of three events. When searching for ideas for a new manga, he wished a machine existed that would come up with ideas for him, he tripped over his daughter's toy, and heard cats fighting in his neighborhood.\n","\n","[ Doc = Doraemon ]\n","Doraemon was awarded the first Shogakukan Manga Award for children's manga in 1982. In 1997, it was awarded the first \u001b[1m\u001b[32mOsamu Tezuka\u001b[0m Culture Award. In 2008, the Japanese Ministry of Foreign Affairs appointed Doraemon as the first anime cultural ambassador.\n","\n",">>> process(\"Who was the first person to set foot on the moon?  \",top_n=3)\n","07/19/2021 06:41:37 PM: [ Processing 1 queries... ]\n","07/19/2021 06:41:37 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 06:41:47 PM: [ Reading 752 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 06:41:55 PM: [ Processed 1 queries in 18.3551 (s) ]\n","Top Predictions:\n","+------+----------------------+----------------------------------+--------------+-----------+\n","| Rank |        Answer        |               Doc                | Answer Score | Doc Score |\n","+------+----------------------+----------------------------------+--------------+-----------+\n","|  1   |    Neil Armstrong    | In the Shadow of the Moon (film) |  1.2422e+09  |   135.32  |\n","|  2   |        Aldrin        |           Buzz Aldrin            |  1.3802e+07  |   143.62  |\n","|  3   | Neil Alden Armstrong |          Neil Armstrong          |  1.8125e+06  |   150.05  |\n","+------+----------------------+----------------------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = In the Shadow of the Moon (film) ]\n","\"In the Shadow of the Moon\" follows the manned missions to the Moon made by the United States in the late 1960s and early 1970s. The documentary reviews both the footage and media available to the public at the time of the missions, as well as NASA films and materials which had not been opened in over 30 years. All of this has been sourced and remastered in HD by the stock footage company Footagevault. Augmenting the archival audio and video are contemporary interviews with some surviving Apollo era astronauts, including Al Bean, Michael Collins, Buzz Aldrin, John Young, David Scott, Charlie Duke, Eugene Cernan and Harrison Schmitt. The former astronauts have the only speaking roles in the movie, although occasional supplementary information is presented on screen with text and archival television footage presents the words of journalists such as Jules Bergman and Walter Cronkite. The only surviving moon walker at the time not to participate was \u001b[1m\u001b[32mNeil Armstrong\u001b[0m, the first person to set foot on the Moon.\n","\n","[ Doc = Buzz Aldrin ]\n","\u001b[1m\u001b[32mAldrin\u001b[0m, a Presbyterian, was the first person to hold a religious ceremony on the Moon. After landing on the Moon, he radioed Earth: \"I'd like to take this opportunity to ask every person listening in, whoever and wherever they may be, to pause for a moment and contemplate the events of the past few hours, and to give thanks in his or her own way.\" He took communion on the surface of the Moon, but he kept it secret because of a lawsuit brought by atheist activist Madalyn Murray O'Hair over the reading of Genesis on Apollo 8. Aldrin, then a church elder, used a home communion kit given to him, and recited words used by his pastor at Webster Presbyterian Church, the Rev. Dean Woodruff. The communion elements were the first food and liquid consumed on the Moon: in \"Guideposts\", Aldrin stated: \"It was interesting to think that the very first liquid ever poured on the Moon, and the first food eaten there, were communion elements.\"\n","\n","[ Doc = Neil Armstrong ]\n","\u001b[1m\u001b[32mNeil Alden Armstrong\u001b[0m (August 5, 1930 – August 25, 2012) was an American astronaut and the first person to walk on the Moon. He was also an aerospace engineer, naval aviator, test pilot, and university professor. Before becoming an astronaut, Armstrong was an officer in the U.S. Navy and served in the Korean War. After the war, he earned his bachelor's degree at Purdue University and served as a test pilot at the National Advisory Committee for Aeronautics (NACA) High-Speed Flight Station, where he logged over 900 flights. He later completed graduate studies at the University of Southern California.\n","\n",">>> process(\"Which team won the 2010 world cup?  \")\n","07/19/2021 07:09:29 PM: [ Processing 1 queries... ]\n","07/19/2021 07:09:29 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 07:09:37 PM: [ Reading 404 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 07:09:42 PM: [ Processed 1 queries in 12.8551 (s) ]\n","Top Predictions:\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","| Rank |     Answer    |                        Doc                         | Answer Score | Doc Score |\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","|  1   | Danny Jordaan | 2009 Republic of Ireland v France football matches |    5332.2    |   210.7   |\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = 2009 Republic of Ireland v France football matches ]\n","According to \"The Independent\", the organiser of the 2010 World Cup \u001b[1m\u001b[32mDanny Jordaan\u001b[0m resisted calls for video refereeing and believed that 'disputed decisions should be considered part of football'. Leslie Irvine, the Northern Irish former referee and FIFA instructor on the referee selection panel for the 2010 World Cup, was of the opinion that referee Hansson was not to blame for the incident, as by simply not seeing the incident he had not committed a 'technical infringement', and said Thierry Henry bore \"moral responsibility\" for the controversy. Jacques Rogge, president of the International Olympic Committee (IOC) praised Henry's decision to express his regrets over the affair, but declined to comment further, having not seen the incident. On the eve of the FIFA EGM, FIFA Secretary General Jérôme Valcke, while lamenting the fact that after 853 matches in the qualifying process, only one was being talked about, he said \"It's important to make sure what happened will not happen again\".\n","\n",">>> process(\"Which team won the 2010 world cup?  \")\n","07/19/2021 07:31:44 PM: [ Processing 1 queries... ]\n","07/19/2021 07:31:44 PM: [ Retrieving top 5 docs... ]\n","07/19/2021 07:31:44 PM: [ Reading 404 paragraphs... ]\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:202: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(y_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:275: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  scores.data.masked_fill_(x_mask.data, -float('inf'))\n","/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/drqa/reader/layers.py:242: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1104.)\n","  xWy.data.masked_fill_(x_mask.data, -float('inf'))\n","07/19/2021 07:31:48 PM: [ Processed 1 queries in 4.8603 (s) ]\n","Top Predictions:\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","| Rank |     Answer    |                        Doc                         | Answer Score | Doc Score |\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","|  1   | Danny Jordaan | 2009 Republic of Ireland v France football matches |    5332.2    |   210.7   |\n","+------+---------------+----------------------------------------------------+--------------+-----------+\n","\n","Contexts:\n","[ Doc = 2009 Republic of Ireland v France football matches ]\n","According to \"The Independent\", the organiser of the 2010 World Cup \u001b[1m\u001b[32mDanny Jordaan\u001b[0m resisted calls for video refereeing and believed that 'disputed decisions should be considered part of football'. Leslie Irvine, the Northern Irish former referee and FIFA instructor on the referee selection panel for the 2010 World Cup, was of the opinion that referee Hansson was not to blame for the incident, as by simply not seeing the incident he had not committed a 'technical infringement', and said Thierry Henry bore \"moral responsibility\" for the controversy. Jacques Rogge, president of the International Olympic Committee (IOC) praised Henry's decision to express his regrets over the affair, but declined to comment further, having not seen the incident. On the eve of the FIFA EGM, FIFA Secretary General Jérôme Valcke, while lamenting the fact that after 853 matches in the qualifying process, only one was being talked about, he said \"It's important to make sure what happened will not happen again\".\n","\n",">>> \n","KeyboardInterrupt\n",">>> Process ForkPoolWorker-6:\n","Traceback (most recent call last):\n","Process ForkPoolWorker-5:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-374c9b3431cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/pipeline/interactive.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   result = _run_command(\n\u001b[0;32m--> 447\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    448\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"Wd-2ZJjoJaNU"},"source":["**NOTE**: PLease allow your browser to allow show pop-ups by sites as show below "]},{"cell_type":"code","metadata":{"id":"UJKOxj0dTulu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626713081149,"user_tz":-420,"elapsed":45614,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"659464a7-a0ac-47a4-d557-84045f4e2d6f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MgzdnEu-XiAJ","executionInfo":{"status":"ok","timestamp":1626327487765,"user_tz":-420,"elapsed":1563326,"user":{"displayName":"Thien Vo Hong","photoUrl":"","userId":"13519670590537774981"}},"outputId":"2d9eb9e5-b14e-4cfa-95a5-ed4c74a6a0b2"},"source":["!python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/eval.py /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/datasets/WikiMovies-test.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/15/2021 05:12:05 AM: [ Reading data ... ]\n","07/15/2021 05:12:06 AM: [ Initializing ranker... ]\n","07/15/2021 05:12:06 AM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x557ee148a000 @  0x7f2cafe1a1e7 0x7f2cac81a46e 0x7f2cac86ac7b 0x7f2cac81dce8 0x557eda8dec65 0x557eda89f559 0x557eda9134f8 0x557eda90d4ae 0x557eda8a03ea 0x557eda90f32a 0x557eda8a23cb 0x557eda8e3599 0x557eda8e350c 0x557eda9864d9 0x557eda90e91e 0x557eda8a030a 0x557eda9127f0 0x557eda90d4ae 0x557eda8a0c9f 0x557eda8e1d79 0x557eda8decc4 0x557eda89f559 0x557eda9134f8 0x557eda90d4ae 0x557eda90d1b3 0x557eda9d7182 0x557eda9d74fd 0x557eda9d73a6 0x557eda9ae723 0x557eda9ae3cc 0x7f2caec04bf7\n","tcmalloc: large alloc 4253114368 bytes == 0x5580dcd48000 @  0x7f2cafe1a1e7 0x7f2cac81a46e 0x7f2cac86ac7b 0x7f2cac81dce8 0x557eda8dec65 0x557eda89f559 0x557eda9134f8 0x557eda90d4ae 0x557eda8a03ea 0x557eda90f32a 0x557eda8a23cb 0x557eda8e3599 0x557eda8e350c 0x557eda9864d9 0x557eda90e91e 0x557eda8a030a 0x557eda9127f0 0x557eda90d4ae 0x557eda8a0c9f 0x557eda8e1d79 0x557eda8decc4 0x557eda89f559 0x557eda9134f8 0x557eda90d4ae 0x557eda90d1b3 0x557eda9d7182 0x557eda9d74fd 0x557eda9d73a6 0x557eda9ae723 0x557eda9ae3cc 0x7f2caec04bf7\n","07/15/2021 05:17:27 AM: [ Ranking... ]\n","07/15/2021 05:20:34 AM: [ Retrieving and computing scores... ]\n","\n","--------------------------------------------------\n","WikiMovies-test.txt\n","Examples:\t\t\t9952\n","Matches in top 5:\t\t6942\n","Match % in top 5:\t\t69.75\n","Total time:\t\t\t1558.4971 (s)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSB-3d_GwMfz","executionInfo":{"status":"ok","timestamp":1626335203430,"user_tz":-420,"elapsed":643920,"user":{"displayName":"Thien Vo Hong","photoUrl":"","userId":"13519670590537774981"}},"outputId":"b3ae981b-b568-4396-f387-fd87d94a4697"},"source":["!python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/eval.py /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/datasets/CuratedTrec-test.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/15/2021 07:36:06 AM: [ Reading data ... ]\n","07/15/2021 07:36:07 AM: [ Initializing ranker... ]\n","07/15/2021 07:36:07 AM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x5629efebc000 @  0x7f208ef9d1e7 0x7f208b99d46e 0x7f208b9edc7b 0x7f208b9a0ce8 0x5629e925cc65 0x5629e921d559 0x5629e92914f8 0x5629e928b4ae 0x5629e921e3ea 0x5629e928d32a 0x5629e92203cb 0x5629e9261599 0x5629e926150c 0x5629e93044d9 0x5629e928c91e 0x5629e921e30a 0x5629e92907f0 0x5629e928b4ae 0x5629e921ec9f 0x5629e925fd79 0x5629e925ccc4 0x5629e921d559 0x5629e92914f8 0x5629e928b4ae 0x5629e928b1b3 0x5629e9355182 0x5629e93554fd 0x5629e93553a6 0x5629e932c723 0x5629e932c3cc 0x7f208dd87bf7\n","tcmalloc: large alloc 4253114368 bytes == 0x562beb7ac000 @  0x7f208ef9d1e7 0x7f208b99d46e 0x7f208b9edc7b 0x7f208b9a0ce8 0x5629e925cc65 0x5629e921d559 0x5629e92914f8 0x5629e928b4ae 0x5629e921e3ea 0x5629e928d32a 0x5629e92203cb 0x5629e9261599 0x5629e926150c 0x5629e93044d9 0x5629e928c91e 0x5629e921e30a 0x5629e92907f0 0x5629e928b4ae 0x5629e921ec9f 0x5629e925fd79 0x5629e925ccc4 0x5629e921d559 0x5629e92914f8 0x5629e928b4ae 0x5629e928b1b3 0x5629e9355182 0x5629e93554fd 0x5629e93553a6 0x5629e932c723 0x5629e932c3cc 0x7f208dd87bf7\n","07/15/2021 07:39:45 AM: [ Ranking... ]\n","07/15/2021 07:40:02 AM: [ Retrieving and computing scores... ]\n","\n","--------------------------------------------------\n","CuratedTrec-test.txt\n","Examples:\t\t\t694\n","Matches in top 5:\t\t217\n","Match % in top 5:\t\t31.27\n","Total time:\t\t\t633.2819 (s)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNsLc4pN4KXY","executionInfo":{"status":"ok","timestamp":1626332857380,"user_tz":-420,"elapsed":1890747,"user":{"displayName":"Thien Vo Hong","photoUrl":"","userId":"13519670590537774981"}},"outputId":"b401d225-f87a-43c1-edb8-c1fec71b156b"},"source":["!python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/eval.py /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/datasets/SQuAD-v1.1-dev.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/15/2021 06:36:13 AM: [ Reading data ... ]\n","07/15/2021 06:36:13 AM: [ Initializing ranker... ]\n","07/15/2021 06:36:13 AM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x55d3af582000 @  0x7f1afc1651e7 0x7f1af8b6546e 0x7f1af8bb5c7b 0x7f1af8b68ce8 0x55d3aa50ac65 0x55d3aa4cb559 0x55d3aa53f4f8 0x55d3aa5394ae 0x55d3aa4cc3ea 0x55d3aa53b32a 0x55d3aa4ce3cb 0x55d3aa50f599 0x55d3aa50f50c 0x55d3aa5b24d9 0x55d3aa53a91e 0x55d3aa4cc30a 0x55d3aa53e7f0 0x55d3aa5394ae 0x55d3aa4ccc9f 0x55d3aa50dd79 0x55d3aa50acc4 0x55d3aa4cb559 0x55d3aa53f4f8 0x55d3aa5394ae 0x55d3aa5391b3 0x55d3aa603182 0x55d3aa6034fd 0x55d3aa6033a6 0x55d3aa5da723 0x55d3aa5da3cc 0x7f1afaf4fbf7\n","tcmalloc: large alloc 4253114368 bytes == 0x55d5aae40000 @  0x7f1afc1651e7 0x7f1af8b6546e 0x7f1af8bb5c7b 0x7f1af8b68ce8 0x55d3aa50ac65 0x55d3aa4cb559 0x55d3aa53f4f8 0x55d3aa5394ae 0x55d3aa4cc3ea 0x55d3aa53b32a 0x55d3aa4ce3cb 0x55d3aa50f599 0x55d3aa50f50c 0x55d3aa5b24d9 0x55d3aa53a91e 0x55d3aa4cc30a 0x55d3aa53e7f0 0x55d3aa5394ae 0x55d3aa4ccc9f 0x55d3aa50dd79 0x55d3aa50acc4 0x55d3aa4cb559 0x55d3aa53f4f8 0x55d3aa5394ae 0x55d3aa5391b3 0x55d3aa603182 0x55d3aa6034fd 0x55d3aa6033a6 0x55d3aa5da723 0x55d3aa5da3cc 0x7f1afaf4fbf7\n","07/15/2021 06:39:56 AM: [ Ranking... ]\n","07/15/2021 06:44:31 AM: [ Retrieving and computing scores... ]\n","\n","--------------------------------------------------\n","SQuAD-v1.1-dev.txt\n","Examples:\t\t\t10570\n","Matches in top 5:\t\t8249\n","Match % in top 5:\t\t78.04\n","Total time:\t\t\t1879.8492 (s)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LIT7MhbBc9r","executionInfo":{"status":"ok","timestamp":1626334366942,"user_tz":-420,"elapsed":752366,"user":{"displayName":"Thien Vo Hong","photoUrl":"","userId":"13519670590537774981"}},"outputId":"25225cc5-6acd-4c45-a3ae-c7267926b719"},"source":["!python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/eval.py /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/datasets/WebQuestions-test.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/15/2021 07:20:22 AM: [ Reading data ... ]\n","07/15/2021 07:20:22 AM: [ Initializing ranker... ]\n","07/15/2021 07:20:22 AM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x558e28bea000 @  0x7f06c53961e7 0x7f06c1d9646e 0x7f06c1de6c7b 0x7f06c1d99ce8 0x558e23abac65 0x558e23a7b559 0x558e23aef4f8 0x558e23ae94ae 0x558e23a7c3ea 0x558e23aeb32a 0x558e23a7e3cb 0x558e23abf599 0x558e23abf50c 0x558e23b624d9 0x558e23aea91e 0x558e23a7c30a 0x558e23aee7f0 0x558e23ae94ae 0x558e23a7cc9f 0x558e23abdd79 0x558e23abacc4 0x558e23a7b559 0x558e23aef4f8 0x558e23ae94ae 0x558e23ae91b3 0x558e23bb3182 0x558e23bb34fd 0x558e23bb33a6 0x558e23b8a723 0x558e23b8a3cc 0x7f06c4180bf7\n","tcmalloc: large alloc 4253114368 bytes == 0x5590244cc000 @  0x7f06c53961e7 0x7f06c1d9646e 0x7f06c1de6c7b 0x7f06c1d99ce8 0x558e23abac65 0x558e23a7b559 0x558e23aef4f8 0x558e23ae94ae 0x558e23a7c3ea 0x558e23aeb32a 0x558e23a7e3cb 0x558e23abf599 0x558e23abf50c 0x558e23b624d9 0x558e23aea91e 0x558e23a7c30a 0x558e23aee7f0 0x558e23ae94ae 0x558e23a7cc9f 0x558e23abdd79 0x558e23abacc4 0x558e23a7b559 0x558e23aef4f8 0x558e23ae94ae 0x558e23ae91b3 0x558e23bb3182 0x558e23bb34fd 0x558e23bb33a6 0x558e23b8a723 0x558e23b8a3cc 0x7f06c4180bf7\n","07/15/2021 07:24:01 AM: [ Ranking... ]\n","07/15/2021 07:24:43 AM: [ Retrieving and computing scores... ]\n","\n","--------------------------------------------------\n","WebQuestions-test.txt\n","Examples:\t\t\t2032\n","Matches in top 5:\t\t1523\n","Match % in top 5:\t\t74.95\n","Total time:\t\t\t741.1074 (s)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D5RGydfo1CZB"},"source":["Evaluate"]},{"cell_type":"markdown","metadata":{"id":"mYKebzejciTZ"},"source":["# Trình đọc tài liệu\n","\n","## Tiền xử lý dữ liệu\n","\n","`preprocess.py` lấy một tập dữ liệu được định dạng SQuAD và xuất ra một tệp đã được tiền xử lý, sẵn sàng cho đào tạo. Đặc biệt, nó xử lý tokenize, ánh xạ các phần bù ký tự thành phần bù mã thông báo, và bất kỳ quá trình trang bị bổ sung nào như lemmazation, POS, và NER.\n","\n","Để tiền xử lý SQuAD ( giả sử cả các tệp input và output trong `data/datasets`):\n","\n","```\n","python scripts/reader/preprocess.py data/datasets data/datasets --split SQuAD-v1.1-train\n","```\n","\n","```\n","python scripts/reader/preprocess.py data/datasets data/datasets --split SQuAD-v1.1-train\n","```\n","\n","* bạn cần có SQuAD train-v1.1.json và dev-v1.1.json trong các data/datasets ( ở đây đã được đổi tên thành SQuAD-v1.1-<train/dev>.json)\n","\n","## Đào tạo\n","\n","`train.py` là tệp lệnh chính cho trình đọc tài liệu.\n","\n","Để bắt đầu với việc huấn luyện một mô hình trên SQuAD với các siêu tham số tốt nhất của chúng tôi:\n","\n","```\n","python scripts/reader/train.py --embedding-file glove.840B.300d.txt --tune-partial 1000\n","```\n","\n","* Bạn cần có [glove embeddings](#note-on-word-embeddings) đã được tải đến data/embeddings/glove.840B.300d.txt.\n","\n","* Bạn cần phải tiền xử lý trước.\n","\n","Việc training có nhiều các tùy chọn mà bạn có thể chỉnh:\n","\n","```\n","Environment:\n","--no-cuda           Đào tạo trên CPU, ngay cả khi GPUs có ẵn. (default: False)\n","--gpu               Chạy trên 1 GPU cụ thể (default: -1)\n","--data-workers      Số lượng quy trình con cho việc tải dữ liệu (default: 5)\n","--parallel          Sử dụng DataParallel trên tất cả các GPU có sẵn (default: False)\n","--random-seed       Hạt giống ngẫu nhiên cho tất cả các hoạt động numpy / torch / cuda (để tái tạo).\n","--num-epochs        Đào tạo lặp lại dữ liệu.\n","--batch-size        Batch size cho việc training.\n","--test-batch-size   Batch size trong quá trình validation/testing.\n","\n","Filesystem:\n","--model-dir         Thư mục cho các models/checkpoints/logs đã được lưu (default: /tmp/drqa-models).\n","--model-name        Mã định dạng mô hình duy nhất (.mdl, .txt, .checkpoint) (default: <generated uuid>).\n","--data-dir          Thư mục của dữ liệu training/validation (default: data/datasets).\n","--train-file        Tệp train đã được tiền xử lý (default: SQuAD-v1.1-train-processed-corenlp.txt).\n","--dev-file          Tệp dev đã được tiền xử lý (default: SQuAD-v1.1-dev-processed-corenlp.txt).\n","--dev-json          tệp dev chưa được xử lý để chạy đánh giá trong khi đào tạo trên (được sử dụng để lấy văn bản gốc để nhận các span và trả lời văn bản) (default: SQuAD-v1.1-dev.json).\n","--embed-dir         Thư mục các tệp nhúng được đào tạo trước (default: data/embeddings).\n","--embedding-file    Tệp nhúng đã được đào tạo trước phân tách bởi dấu cách (default: None).\n","\n","Saving/Loading:\n","--checkpoint        Lưu trạng thái model + optimizer sau mỗi epoch (default: False).\n","--pretrained        Đường dẫn đến mô hình được đào tạo trước để bắt đầu với (default: <empty>).\n","--expand-dictionary Mở rộng từ điển của mô hình đào tạo trước (--pretrained) để bao gồm các từ của data mới training/dev (default: False).\n","\n","Preprocessing:\n","--uncased-question  Question words will be lower-cased (default: False).\n","--uncased-doc       Document words will be lower-cased (default: False).\n","--restrict-vocab    Only use pre-trained words in embedding_file (default: True).\n","\n","General:\n","--official-eval     Validate with official SQuAD eval (default: True).\n","--valid-metric      The evaluation metric used for model selection (default: f1).\n","--display-iter      Log state after every <display_iter> epochs (default: 25).\n","--sort-by-len       Sort batches by length for speed (default: True).\n","\n","DrQA Reader Model Architecture:\n","--model-type        Model architecture type (default: rnn).\n","--embedding-dim     Embedding size if embedding_file is not given (default: 300).\n","--hidden-size       Hidden size of RNN units (default: 128).\n","--doc-layers        Number of encoding layers for document (default: 3).\n","--question-layers   Number of encoding layers for question (default: 3).\n","--rnn-type          RNN type: LSTM, GRU, or RNN (default: lstm).\n","\n","DrQA Reader Model Details:\n","--concat-rnn-layers Combine hidden states from each encoding layer (default: True).\n","--question-merge    The way of computing the question representation (default: self_attn).\n","--use-qemb          Whether to use weighted question embeddings (default: True).\n","--use-in-question   Whether to use in_question_* (cased, uncased, lemma) features (default: True).\n","--use-pos           Whether to use pos features (default: True).\n","--use-ner           Whether to use ner features (default: True).\n","--use-lemma         Whether to use lemma features (default: True).\n","--use-tf            Whether to use term frequency features (default: True).\n","\n","DrQA Reader Optimization:\n","--dropout-emb           Dropout rate for word embeddings (default: 0.4).\n","--dropout-rnn           Dropout rate for RNN states (default: 0.4).\n","--dropout-rnn-output    Whether to dropout the RNN output (default: True).\n","--optimizer             Optimizer: sgd or adamax (default: adamax).\n","--learning-rate         Learning rate for SGD only (default: 0.1).\n","--grad-clipping         Gradient clipping (default: 10).\n","--weight-decay          Weight decay factor (default: 0).\n","--momentum              Momentum factor (default: 0).\n","--fix-embeddings        Keep word embeddings fixed (use pretrained) (default: True).\n","--tune-partial          Backprop through only the top N question words (default: 0).\n","--rnn-padding           Explicitly account for padding (and skip it) in RNN encoding (default: False).\n","--max-len MAX_LEN       The max span allowed during decoding (default: 15).\n","```\n","\n","### Lưu ý trên các Word Embedding\n","\n","Sử dụng các word embedding được đào tạo trước rất quan trọng cho hiệu suất. Các mô hình mà chúng tôi cung cấp đã được đào tạo với cách nhúng GloVe được đào tạo trên Common Crawl, tuy nhiên, chúng tôi cũng nhận thấy rằng các cách nhúng khác như FastText hoạt động khá tốt.\n","\n","Chúng tôi khuyên bạn nên tải xuống các tệp nhúng và lưu trữ chúng dưới dạng `data/embeddings/<file>.txt` (đây là tệp mặc định cho `--embedding-dir`). Mã mong đợi các tệp văn bản thuần túy được phân tách bằng khoảng trắng (<token> <d1> ... <dN>).\n","\n","- [GloVe: Common Crawl (cased)](http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip)\n","- [FastText: Wikipedia (uncased)](https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip)\n","\n","## Dự đoán\n","\n","`predict.py` sử dụng mô hình Trình đọc tài liệu được đào tạo để đưa ra dự đoán cho tập dữ liệu đầu vào.\n","\n","Các đối số được yêu cầu:\n","\n","```\n","dataset               SQuAD-like dataset to evaluate on (format B).\n","```\n","\n","Các đối số tùy chọn:\n","\n","```\n","--model             Path to model to use.\n","--embedding-file    Expand dictionary to use all pretrained embeddings in this file.\n","--out-dir           Directory to write prediction file to (<dataset>-<model>.preds).\n","--tokenizer         String option specifying tokenizer type to use (e.g. 'corenlp').\n","--num-workers       Number of CPU processes (for tokenizing, etc).\n","--no-cuda           Use CPU only.\n","--gpu               Specify GPU device id to use.\n","--batch-size        Example batching size (Reduce in case of OOM).\n","--top-n             Store top N predicted spans per example.\n","--official          Only store single top span instead of top N list. (The SQuAD eval script takes a dict of qid: span).\n","```\n","\n","*Lưu ý*: Chú thích CoreNLP NER không hoàn toàn xác định( dựa trên thứ tự các ví dụ được tiền xử lý). Các dự đoán có thể dao động rất nhẹ giữa các lần chạy nếu `num-workers` > 1 và mô hình được đào tạo với `use-ner`.\n","\n","Đánh giá được thực hiện với tập lệnh Official_eval.py từ những người tạo SQuAD, có sẵn tại [đây](https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents/blob/). Nó cũng có sẵn theo mặc định tại `scripts/reader/official_eval.py` sau khi chạy `./download.sh.`\n","\n","```\n","python scripts/reader/official_eval.py /path/to/format/B/dataset.json /path/to/predictions/with/--official/flag/set.json\n","```\n","\n","## Tương tác\n","\n","Trình đọc tài liệu cũng có thể được sử dụng một cách tương tác( giống như [full pipeline](../../README.md#quick-start-demo)).\n","\n","```bash\n","python scripts/reader/interactive.py --model /path/to/model\n","```\n","\n","```\n",">>> text = \"Mary had a little lamb, whose fleece was white as snow. And everywhere that Mary went the lamb was sure to go.\"\n",">>> question = \"What color is Mary's lamb?\"\n",">>> process(text, question)\n","\n","+------+-------+---------+\n","| Rank |  Span |  Score  |\n","+------+-------+---------+\n","|  1   | white | 0.78002 |\n","+------+-------+---------+\n","```"]},{"cell_type":"code","metadata":{"id":"buIEYGHKsZ_q"},"source":["%%shell\n","#!/bin/bash\n","# Copyright 2017-present, Facebook, Inc.\n","# All rights reserved.\n","#\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","\n","set -e\n","\n","# By default download to the data directory I guess\n","read -p \"Specify download path or enter to use default (data/corenlp): \" path\n","DOWNLOAD_PATH=\"${path:-data/corenlp}\"\n","echo \"Will download to: $DOWNLOAD_PATH\"\n","\n","# Download zip, unzip\n","pushd \"/tmp\"\n","wget -O \"stanford-corenlp-full-2017-06-09.zip\" \"http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\"\n","unzip \"stanford-corenlp-full-2017-06-09.zip\"\n","rm \"stanford-corenlp-full-2017-06-09.zip\"\n","popd\n","\n","# Put jars in DOWNLOAD_PATH\n","mkdir -p \"$DOWNLOAD_PATH\"\n","mv \"/tmp/stanford-corenlp-full-2017-06-09/\"*\".jar\" \"$DOWNLOAD_PATH/\"\n","\n","# Append to bashrc, instructions\n","while read -p \"Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: \" choice; do\n","    case \"$choice\" in\n","        yes )\n","            echo \"export CLASSPATH=\\$CLASSPATH:$DOWNLOAD_PATH/*\" >> ~/.bashrc;\n","            break ;;\n","        no )\n","            break ;;\n","        * ) echo \"Please answer yes or no.\" ;;\n","    esac\n","done\n","\n","printf \"\\n*** NOW RUN: ***\\n\\nexport CLASSPATH=\\$CLASSPATH:$DOWNLOAD_PATH/*\\n\\n****************\\n\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy9KW4a27wHT","executionInfo":{"status":"ok","timestamp":1624781703067,"user_tz":-420,"elapsed":308,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"9c5a8ea1-9816-45a1-a5e4-db3ead8d3a27"},"source":["%%shell\n","export CLASSPATH=$CLASSPATH:/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/Core_NLP/\\*"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"t2QlZVd08Asv"},"source":["%%shell\n","echo $CLASSPATH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFVENFMQv1MT"},"source":["from drqa.tokenizers import CoreNLPTokenizer\n","tok = CoreNLPTokenizer()\n","tok.tokenize('hello world').words() # Should complete immediately"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUcAtUw9mjRp","executionInfo":{"status":"ok","timestamp":1624782831148,"user_tz":-420,"elapsed":14800,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"bb9d96ad-eca8-41eb-d5fc-50e2527246db"},"source":["import os       #importing os to set environment variable\n","def install_java():\n","  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n","  !java -version       #check java version\n","install_java()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tqwd5eFotYMu","executionInfo":{"status":"ok","timestamp":1624781716959,"user_tz":-420,"elapsed":11823,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"3eb42deb-3078-4d51-b31e-3acf66287332"},"source":["import drqa.tokenizers\n","drqa.tokenizers.set_default('spacy_classpath', '/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/Core_NLP/*')\n","print('Run')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Run\n"],"name":"stdout"}]}]}