{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PleaseWork.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Bt7lbIerZRkul95IqsJaDINeecol-bnn","authorship_tag":"ABX9TyMmkHhoWpnz7eo5qE4znR9F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"145l3pBR8myE"},"source":["# Giới thiệu\n","\n","DrQA là một hệ thống cho việc đọc hiểu được áp dụng để trả lời câu hỏi mã nguồn mở. Cụ thể, DrQA nhằm mục đích giải quyết nhiệm vụ đọc máy quy mô lớn. Trong phần cài đặt, chúng tôi tìm kiếm câu trả lời của một câu hỏi trong một kho tài liệu có khả năng cao của các tài liệu phi cấu trúc. Vì thế, hệ thống phải kết hợp cả thách thức trích xuất và hiểu máy một đoạn văn bản.\n","\n","Thực nghiệm với DrQA tập trung vào việc trả lời các câu hỏi thực tế trong khi sử dụng Wikipedia như nguồn kiến thức duy nhất cho các tài liệu. Wikipedia là một nguồn phong phú, chi tiết, phù hợp quy mô lớn. Để trả lời bất kỳ câu hỏi nào, đầu tiên phải trích xuất các bài báo chung trong hơn 5 triệu bài, và sau đó quét chúng cẩn thẩn, để xác định câu trả lời.\n","\n","Lưu ý rằng DrQA coi Wikipeadia như tập hợp các bài báo chung và không dựa vào cấu trúc đồ thị bên trong. Do đó, **DrQA có thể được áp dụng dễ dàng cho bất kỳ bộ sưu tập tài liệu nào**. Trong phần trích xuất tài liệu README có mô tả chi tiết.\n","\n","Kho tài liệu này bao gồm code, dữ liệu và mô hình tiền huấn luyện cho tiền xử lý và truy vấn Wikipedia như được mô tả trong bài báo -- Xem Mô hình được train và dữ liệu. Chúng tôi cũng liệt kê một số bộ dữ liệu khác nhau cho việc đánh giá, xem phần các bộ dữ liệu QA. Lưu ý rằng công việc này là được cấu trúc lại và hiệu quả hơn phiên bản code gốc. Các con số sản phẩm rất giống nhau nhưng không hoàn toàn."]},{"cell_type":"code","metadata":{"id":"XCdoLENU6ai4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624589417750,"user_tz":-420,"elapsed":1174,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"9123f076-f846-4620-e7f4-3e9c4ceadfa2"},"source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA')\n","print('Kết nối đến thư mục code thành công') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Kết nối đến thư mục code thành công\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s_1FoJUR7wyQ"},"source":["## Cài đặt drqa\n","\n","DrQA yêu cầu sử dụng Linux/OSX và python 3.5 trở lên. Nó cũng yêu cầu PyTorch phiên bản 1.0. Nó dựa trên các thư viện khác được liệt kê trong file requirements.txt. CUDA là được yêu cầu mạnh mẽ cho tốc độ, nhưng không bắt buộc.\n","\n","Chạy câu lệnh sau đây để clone reposity về và cài đặt DrQA:\n","\n","```\n","git clone https://github.com/facebookresearch/DrQA.git\n","cd DrQA; pip install -r requirements.txt; python setup.py develop\n","```\n","\n","Lưu ý: requirements.txt bao gồm một tập con tất cả các gói có thể được yêu cầu. \n","\n","Tùy thuộc vào cái bạn muốn chạy, bạn có thể cần cài đặt thêm các gói( ví dụ spacy)\n","\n","Nếu bạn sử dụng CoreNLP Tokenizer hoặc SpacyTokenizer bạn sẽ cần cài đặt Stanford CoreNLP jars và mô hình spaCy en tương ứng. Nếu bạn dùng Stanford CoreNLP, có jars trong biến môi trường CLASSPATH trong java của bạn, hoặc đặt đường dẫn tự động với:\n","\n","```\n","import drqa.tokenizers\n","drqa.tokenizers.set_default('corenlp_classpath', 'your/corenlp/classpath/*')\n","```\n","\n","**Quan trọng: Tokenizer mặc định là CoreNLP nên bạn sẽ cần điều đó trong CLASSPATH để chạy các ví dụ ở phần README**\n","\n","Vd: ```export CLASSPATH=$CLASSPATH:/path/to/corenlp/download/* ```\n","\n","Nếu bạn chưa cài đặt CoreNLP thì có thể chạy:\n","```\n","./install_corenlp.sh\n","```\n","\n","Xác nhận xem nó có chạy không bằng :\n","\n","```\n","from drqa.tokenizers import CoreNLPTokenizer\n","tok = CoreNLPTokenizer()\n","tok.tokenize('hello world').words() # Should complete immediately\n","```\n","\n","Để thuận tiện, mô hình trình đọc tài liệu, trích xuất và Pipeline sẽ cố gắng load các mô hình mặc định nếu không có đối số mô hình được truyền vào. Xem phía dưới cho việc cài đặt các mô hình này."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8is0mrdvxpz","executionInfo":{"status":"ok","timestamp":1624589421206,"user_tz":-420,"elapsed":3470,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"3f5d5664-6e8d-403f-e241-870db8f00b3a"},"source":["pip install elasticsearch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting elasticsearch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/b1/58cfb0bf54e29c20669d6e588496fb7fe8b54f53bc238be4cb0a185a1e76/elasticsearch-7.13.1-py2.py3-none-any.whl (354kB)\n","\r\u001b[K     |█                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 276kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 286kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 296kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 307kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 317kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 327kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 337kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 348kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2021.5.30)\n","Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n","Installing collected packages: elasticsearch\n","Successfully installed elasticsearch-7.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDfLcOoyu4fz"},"source":["import numpy\n","import sklearn\n","import termcolor\n","import regex\n","import tqdm\n","import prettytable\n","import scipy\n","import nltk\n","import elasticsearch\n","import spacy\n","# import pexpect==4.2.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVWhssx-gEc8","executionInfo":{"status":"ok","timestamp":1624261283506,"user_tz":-420,"elapsed":2380,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"88d10be1-5854-4d07-f1c9-7d589824f196"},"source":["import os       #importing os to set environment variable\n","def install_java():\n","  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n","  !java -version       #check java version\n","install_java()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.11\" 2021-04-20\n","OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n","OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LC48UJehwK0G","executionInfo":{"status":"ok","timestamp":1624268154527,"user_tz":-420,"elapsed":14550,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"b748f4cc-6b4d-4159-f0f4-4b0a05ecf984"},"source":["import drqa.tokenizers\n","drqa.tokenizers.set_default('corenlp_classpath', '/content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/')\n","print('OK')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yG0vyXNhTJjG"},"source":["from drqa.tokenizers import spacy_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4cW8tghVNpl"},"source":["import sys\n","sys.path.append('/.../application/app/folder')\n","import file_1\n","\n","import sys\n","sys.path.insert(1, '/.../application/app/folder')\n","import file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFqZ7Hm54pxy","executionInfo":{"status":"ok","timestamp":1624261594345,"user_tz":-420,"elapsed":116546,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"8eeabcb3-addb-4291-aea8-4cde04e50da7"},"source":["%%shell\n","#!/bin/bash\n","# Copyright 2017-present, Facebook, Inc.\n","# All rights reserved.\n","#\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","\n","set -e\n","\n","\n","# export CLASSPATH=$CLASSPATH:/content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/*\n","# By default download to the data directory I guess\n","read -p \"Specify download path or enter to use default (data/corenlp): \" path\n","DOWNLOAD_PATH=\"${path:-data/corenlp}\"\n","echo \"Will download to: $DOWNLOAD_PATH\"\n","\n","# Download zip, unzip\n","pushd \"/tmp\"\n","wget -O \"stanford-corenlp-full-2017-06-09.zip\" \"http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\"\n","unzip \"stanford-corenlp-full-2017-06-09.zip\"\n","rm \"stanford-corenlp-full-2017-06-09.zip\"\n","popd\n","\n","# Put jars in DOWNLOAD_PATH\n","mkdir -p \"$DOWNLOAD_PATH\"\n","mv \"/tmp/stanford-corenlp-full-2017-06-09/\"*\".jar\" \"$DOWNLOAD_PATH/\"\n","\n","# Append to bashrc, instructions\n","while read -p \"Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: \" choice; do\n","    case \"$choice\" in\n","        yes )\n","            echo \"export CLASSPATH=\\$CLASSPATH:$DOWNLOAD_PATH/*\" >> ~/.bashrc;\n","            break ;;\n","        no )\n","            break ;;\n","        * ) echo \"Please answer yes or no.\" ;;\n","    esac\n","done\n","\n","printf \"\\n*** NOW RUN: ***\\n\\nexport CLASSPATH=\\$CLASSPATH:$DOWNLOAD_PATH/*\\n\\n****************\\n\"\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Specify download path or enter to use default (data/corenlp): /content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/*\n","Will download to: /content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/*\n","/tmp /content\n","--2021-06-21 07:44:44--  http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip [following]\n","--2021-06-21 07:44:44--  https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip [following]\n","--2021-06-21 07:44:45--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 390211140 (372M) [application/zip]\n","Saving to: ‘stanford-corenlp-full-2017-06-09.zip’\n","\n","stanford-corenlp-fu 100%[===================>] 372.13M  5.05MB/s    in 70s     \n","\n","2021-06-21 07:45:54 (5.33 MB/s) - ‘stanford-corenlp-full-2017-06-09.zip’ saved [390211140/390211140]\n","\n","Archive:  stanford-corenlp-full-2017-06-09.zip\n","   creating: stanford-corenlp-full-2017-06-09/\n","  inflating: stanford-corenlp-full-2017-06-09/xom-1.2.10-src.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/CoreNLP-to-HTML.xsl  \n","  inflating: stanford-corenlp-full-2017-06-09/README.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/jollyday-0.4.9-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/LIBRARY-LICENSES  \n","   creating: stanford-corenlp-full-2017-06-09/sutime/\n","  inflating: stanford-corenlp-full-2017-06-09/sutime/defs.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/sutime/english.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/sutime/english.holidays.sutime.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-javadoc.jar  \n"," extracting: stanford-corenlp-full-2017-06-09/ejml-0.23-src.zip  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-models.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/input.txt.xml  \n","  inflating: stanford-corenlp-full-2017-06-09/build.xml  \n","  inflating: stanford-corenlp-full-2017-06-09/pom.xml  \n","   creating: stanford-corenlp-full-2017-06-09/tokensregex/\n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.input.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/retokenize.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.properties  \n","  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.rules.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/javax.json-api-1.0-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/protobuf.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/StanfordDependenciesManual.pdf  \n","   creating: stanford-corenlp-full-2017-06-09/patterns/\n","  inflating: stanford-corenlp-full-2017-06-09/patterns/example.properties  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/otherpeople.txt  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/goldplaces.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/stopwords.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/presidents.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/names.txt  \n"," extracting: stanford-corenlp-full-2017-06-09/patterns/places.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/patterns/goldnames.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/slf4j-simple.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/input.txt  \n","  inflating: stanford-corenlp-full-2017-06-09/joda-time.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/xom.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/StanfordCoreNlpDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/slf4j-api.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/ejml-0.23.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/javax.json.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/Makefile  \n","  inflating: stanford-corenlp-full-2017-06-09/corenlp.sh  \n","  inflating: stanford-corenlp-full-2017-06-09/joda-time-2.9-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-sources.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/jollyday.jar  \n","  inflating: stanford-corenlp-full-2017-06-09/ShiftReduceDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/SemgrexDemo.java  \n","  inflating: stanford-corenlp-full-2017-06-09/LICENSE.txt  \n","/content\n","Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: yes\n","\n","*** NOW RUN: ***\n","\n","export CLASSPATH=$CLASSPATH:/content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/*/*\n","\n","****************\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgyVtKKL4uAl","executionInfo":{"status":"ok","timestamp":1624589441333,"user_tz":-420,"elapsed":15579,"user":{"displayName":"Nhan Dang Van","photoUrl":"","userId":"05909789488592646674"}},"outputId":"40f6c1c9-6882-4b79-ab89-20e8249f1d77"},"source":["from drqa.tokenizers import SpacyTokenizer\n","tok = SpacyTokenizer()\n","tok.tokenize('hello world').words() # Should complete immediately"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', 'world']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ijv-Hrs9zxTI"},"source":["%%shell\n","#!/bin/bash\n","# Copyright 2017-present, Facebook, Inc.\n","# All rights reserved.\n","#\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","\n","set -e\n","\n","# Configure download location\n","DOWNLOAD_PATH=\"/content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data\"\n","\n","# Get AWS hosted data\n","DOWNLOAD_PATH_TAR=\"$DOWNLOAD_PATH.tar.gz\"\n","\n","# Download main hosted data\n","# wget -O \"$DOWNLOAD_PATH_TAR\" \"https://dl.fbaipublicfiles.com/drqa/data.tar.gz\"\n","\n","# Untar\n","tar -xvf \"$DOWNLOAD_PATH_TAR\"\n","\n","# Remove tar ball\n","rm \"$DOWNLOAD_PATH_TAR\"\n","\n","# Get externally hosted data\n","DATASET_PATH=\"/content/drive/MyDrive/Đồ án cuối kì - Xử lý ngôn ngữ tự nhiên/NLP- perfect version/DrQA/download_data/datasets\"\n","\n","# Get SQuAD train\n","wget -O \"$DATASET_PATH/SQuAD-v1.1-train.json\" \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n","python scripts/convert/squad.py \"$DATASET_PATH/SQuAD-v1.1-train.json\" \"$DATASET_PATH/SQuAD-v1.1-train.txt\"\n","\n","# Get SQuAD dev\n","wget -O \"$DATASET_PATH/SQuAD-v1.1-dev.json\" \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n","python scripts/convert/squad.py \"$DATASET_PATH/SQuAD-v1.1-dev.json\" \"$DATASET_PATH/SQuAD-v1.1-dev.txt\"\n","\n","# Download official eval for SQuAD\n","curl \"https://worksheets.codalab.org/rest/bundles/0xbcd57bee090b421c982906709c8c27e1/contents/blob/\" >  \"./scripts/reader/official_eval.py\"\n","\n","# Get WebQuestions train\n","wget -O \"$DATASET_PATH/WebQuestions-train.json.bz2\" \"http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.train.json.bz2\"\n","bunzip2 -f \"$DATASET_PATH/WebQuestions-train.json.bz2\"\n","python scripts/convert/webquestions.py \"$DATASET_PATH/WebQuestions-train.json\" \"$DATASET_PATH/WebQuestions-train.txt\"\n","rm \"$DATASET_PATH/WebQuestions-train.json\"\n","\n","# Get WebQuestions test\n","wget -O \"$DATASET_PATH/WebQuestions-test.json.bz2\" \"http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.test.json.bz2\"\n","bunzip2 -f \"$DATASET_PATH/WebQuestions-test.json.bz2\"\n","python scripts/convert/webquestions.py \"$DATASET_PATH/WebQuestions-test.json\" \"$DATASET_PATH/WebQuestions-test.txt\"\n","rm \"$DATASET_PATH/WebQuestions-test.json\"\n","\n","# Get freebase entities for WebQuestions\n","wget -O \"$DATASET_PATH/freebase-entities.txt.gz\" \"https://dl.fbaipublicfiles.com/drqa/freebase-entities.txt.gz\"\n","gzip -d \"$DATASET_PATH/freebase-entities.txt.gz\"\n","\n","echo \"DrQA download done!\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXY6secg70am"},"source":["## Đào tạo mô hình và dữ liệu\n","\n","Để tải tất cả các mô hình đã đào tạo được cung cấp và dữ liệu cho trả lời câu hỏi Wikipedia, chạy:\n","\n","```\n","./download.sh\n","```\n","*Cảnh báo: this downloads a 7.5GB tarball (25GB untarred) và sẽ mất một khoảng thời gian.*\n","\n","Cấu trúc, vị trí tải:\n","\n","\n","\n","```\n","DrQA\n","├── data (or $DRQA_DATA)\n","    ├── datasets\n","    │   ├── SQuAD-v1.1-<train/dev>.<txt/json>\n","    │   ├── WebQuestions-<train/test>.txt\n","    │   ├── freebase-entities.txt\n","    │   ├── CuratedTrec-<train/test>.txt\n","    │   └── WikiMovies-<train/test/entities>.txt\n","    ├── reader\n","    │   ├── multitask.mdl\n","    │   └── single.mdl\n","    └── wikipedia\n","        ├── docs.db\n","        └── docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz\n","```\n","\n","Các đường dẫn mô hình mặc định cho các mô đun khác nhau cũng có thể được chỉnh sửa tự động trong code, ví dụ:\n","\n","```\n","import drqa.reader\n","drqa.reader.set_default('model', '/path/to/model')\n","reader = drqa.reader.Predictor() # Mô hình mặc định được tải cho việc dự đoán\n","```\n"]},{"cell_type":"code","metadata":{"id":"4IxAs4By7OsE"},"source":["import drqa.reader\n","drqa.reader.set_default('model', '/content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/reader/single.mdl')\n","reader = drqa.reader.Predictor() # Mô hình mặc định được tải cho việc dự đoán\n","print('chạy xong')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7kzVLK_Wd7SQ"},"source":["## Trình trích xuất tài liệu\n","\n","Mô hình TF-IDF sử dụng Wikipedia( unigrams và bigrams, 2^24 bins, tokenization đơn giản), được đánh giá trên nhiều bộ dữ liệu( bộ test, bộ dev cho SQuAD):\n","\n","| Model | SQuAD P@5 | CuratedTREC P@5 | WebQuestions P@5 | WikiMovies P@5 | Size |\n","| :---: | :-------: | :-------------: | :--------------: | :------------: | :---: |\n","| [TF-IDF model](https://dl.fbaipublicfiles.com/drqa/docs-tfidf-ngram%3D2-hash%3D16777216-tokenizer%3Dsimple.npz.gz) | 78.0 | 87.6 | 75.0 | 69.8 | ~13GB |\n","\n","P@5 ở đây là được định nghĩa như % các câu hỏi cho các phần câu trả lời xuất hiện trong top5 tài liệu"]},{"cell_type":"markdown","metadata":{"id":"ri5ldZ0re1pF"},"source":["## Trình đọc tài liệu\n","\n","Mô hinh được huấn luyện chỉ trên bộ SQuAD, được đánh giá trong cài đặt SQuAD:\n","\n","| Model | SQuAD Dev EM | SQuAD Dev F1 | Size |\n","| :---: | :-----------:| :----------: | :--: |\n","| [Single model](https://dl.fbaipublicfiles.com/drqa/single.mdl) | 69.4 | 78.9 | ~130MB |\n","\n","Mô hình được đào tạo với giám sát từ xa mà không có các tính năng NER/POS/lemma, được đánh giá trên nhiều bộ dữ liệu( bộ test, bộ dev cho SQuAD) trong cài đặt đầy đủ Wikipedia:\n","\n","| Model | SQuAD EM | CuratedTREC EM | WebQuestions EM | WikiMovies EM | Size |\n","| :---: | :------: | :------------: | :-------------: | :-----------: | :--:\n","| [Multitask model](https://dl.fbaipublicfiles.com/drqa/multitask.mdl) | 29.5 | 27.2 | 18.5 | 36.9 | ~270MB |\n","\n"]},{"cell_type":"code","metadata":{"id":"t8PjyQpVfebT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0aNi4mhafjyx"},"source":["## Wikipedia\n","\n","Các thử nghiệm quy mô đầy đủ của chúng tôi được thực hiện trên Wikipedia tiếng Anh 2016-12-21. Kết xuất được xử lý bằng WikiExtractor và được lọc cho các trang nội bộ, danh sách, chỉ mục và phác thảo (các trang thường chỉ là liên kết). Chúng tôi lưu trữ các tài liệu trong cơ sở dữ liệu sqlite mà drqa.retriever.DocDB cung cấp một giao diện.\n","\n","| Database | Num. Documents | Size |\n","| :------: | :------------: | :-----------------: |\n","| [Wikipedia](https://dl.fbaipublicfiles.com/drqa/docs.db.gz) | 5,075,182 | ~13GB |\n","\n","## QA Datasets\n","\n","Các bộ dữ liệu được sử dụng cho đào tạo và đánh giá DrQA có thể được tìm thấy ở đây:\n","\n","- SQuAD: [train](https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json), [dev](https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json)\n","- WebQuestions: [train](http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.train.json.bz2), [test](http://nlp.stanford.edu/static/software/sempre/release-emnlp2013/lib/data/webquestions/dataset_11/webquestions.examples.test.json.bz2), [entities](https://dl.fbaipublicfiles.com/drqa/freebase-entities.txt.gz)\n","- WikiMovies: [train/test/entities](https://dl.fbaipublicfiles.com/drqa/WikiMovies.tar.gz)\n","(Rehosted in expected format from https://research.fb.com/downloads/babi/)\n","- CuratedTrec: [train/test](https://dl.fbaipublicfiles.com/drqa/CuratedTrec.tar.gz)\n","(Rehosted in expected format from https://github.com/brmson/dataset-factoid-curated)\n","\n","**Định dạng A**\n","\n","Các tập lệnh\n","    retriever/eval.py, pipeline/eval.py\n","và \n","    distant/generate.py\n","\n","mong đợi các bộ dữ liệu như file .txt mà mỗi dòng là một cặp QA được mã hóa JSON, giống như này:\n","\n","```python\n","'{\"question\": \"q1\", \"answer\": [\"a11\", ..., \"a1i\"]}'\n","...\n","'{\"question\": \"qN\", \"answer\": [\"aN1\", ..., \"aNi\"]}'\n","```\n","\n","Các tập lệnh để chuyển SQuAD và WebQuestion thành định dạng này là được bao gồm trong\n","    scripts/convert\n","Điều này tự động làm trong *download.sh*\n","\n","**Định dạng B**\n","\n","Các tập lệnh thư mục *reader* mong đợi các tập dữ liệu dưới dạng tệp .json, nơi dữ liệu được sắp xếp giống SQuAD:\n","\n","```\n","file.json\n","├── \"data\"\n","│   └── [i]\n","│       ├── \"paragraphs\"\n","│       │   └── [j]\n","│       │       ├── \"context\": \"paragraph text\"\n","│       │       └── \"qas\"\n","│       │           └── [k]\n","│       │               ├── \"answers\"\n","│       │               │   └── [l]\n","│       │               │       ├── \"answer_start\": N\n","│       │               │       └── \"text\": \"answer\"\n","│       │               ├── \"id\": \"<uuid>\"\n","│       │               └── \"question\": \"paragraph question?\"\n","│       └── \"title\": \"document id\"\n","└── \"version\": 1.1\n","```\n","\n","## Danh sách thực thể\n","Một số bộ dữ liệu có danh sách ứng viên (có thể lớn) để chọn câu trả lời. Ví dụ: câu trả lời của WikiMovies là các mục nhập OMDb trong khi WebQuestions dựa trên Freebase. Nếu chúng tôi biết các ứng cử viên, chúng tôi có thể áp đặt rằng tất cả các câu trả lời được dự đoán phải nằm trong danh sách này bằng cách loại bỏ bất kỳ khoảng(span) nào mà điểm cao hơn là không có."]},{"cell_type":"code","metadata":{"id":"_lZ2Rqe2iLdQ"},"source":["import sys\n","sys.path.append('/.../application/app/folder')\n","!python scripts/reader/interactive.py --model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1N5H6gt5IZNC"},"source":["i = []\n","while True:\n","    i.append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"If84nocee1DV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6c23879-5163-49a1-823c-9f039a87fff6"},"source":["! python /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/scripts/retriever/interactive.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/25/2021 02:51:43 AM: [ Initializing ranker... ]\n","06/25/2021 02:51:43 AM: [ Loading /content/drive/MyDrive/ProjectNLP/NLP_Perfect/DrQA/data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz ]\n","tcmalloc: large alloc 8506228736 bytes == 0x563af902a000 @  0x7fefb7cf91e7 0x7fefb3b9d46e 0x7fefb3bedc7b 0x7fefb3ba0ce8 0x563af2ddfc65 0x563af2da0559 0x563af2e144f8 0x563af2e0e4ae 0x563af2da13ea 0x563af2e1032a 0x563af2da33cb 0x563af2de4599 0x563af2de450c 0x563af2e874d9 0x563af2e0f91e 0x563af2da130a 0x563af2e137f0 0x563af2e0e4ae 0x563af2da1c9f 0x563af2de2d79 0x563af2ddfcc4 0x563af2da0559 0x563af2e144f8 0x563af2e0e4ae 0x563af2e0e1b3 0x563af2ed8182 0x563af2ed84fd 0x563af2ed83a6 0x563af2eaf723 0x563af2eaf3cc 0x7fefb6ae3bf7\n","tcmalloc: large alloc 4253114368 bytes == 0x563cf491a000 @  0x7fefb7cf91e7 0x7fefb3b9d46e 0x7fefb3bedc7b 0x7fefb3ba0ce8 0x563af2ddfc65 0x563af2da0559 0x563af2e144f8 0x563af2e0e4ae 0x563af2da13ea 0x563af2e1032a 0x563af2da33cb 0x563af2de4599 0x563af2de450c 0x563af2e874d9 0x563af2e0f91e 0x563af2da130a 0x563af2e137f0 0x563af2e0e4ae 0x563af2da1c9f 0x563af2de2d79 0x563af2ddfcc4 0x563af2da0559 0x563af2e144f8 0x563af2e0e4ae 0x563af2e0e1b3 0x563af2ed8182 0x563af2ed84fd 0x563af2ed83a6 0x563af2eaf723 0x563af2eaf3cc 0x7fefb6ae3bf7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4pZp7DyQINkL"},"source":["! python scripts/retriever/eval.py /path/to/format/A/dataset.txt --model /path/to/model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kTNEHjDqiMB3"},"source":["# DrQA Components\n","\n","## Document Retriever\n","\n","DrQA không bị ràng buộc bởi bất kỳ loại hệ thống truy xuất cụ thể nào -- miễn là nó thu hẹp không gian tìm kiếm một cách hiệu quả và tập trung vào các tài liệu liên quan.\n","\n","Theo các hệ thống QA cổ điển, chúng tôi bao gồm một hệ thống truy xuất tài liệu dựa trên các vector tú từ có trọng số TF-IDF thưa thớt( không dùng máy học). Chúng tôi dùng thêm các túi được băm n-grams( ở đây là unigrams và bigrams).\n","\n","Để xem cách xây dựng mô hình như vậy của riêng bạn trên các tài liệu mới, hãy xem README của trình trích xuất.\n","\n","Để truy vấn Wikipedia có thể tương tác:\n","\n","```\n","python scripts/retriever/interactive.py --model /path/to/model\n","```\n","\n","Nếu *model* đã \"rời khỏi\", mô hình mặc định của chúng tôi sẽ được sử dụng( giả sử nó đã được tải).\n","\n","Để đánh giá tỉ lệ trích xuất( % phù hợp trong top 5) trên bộ dữ liệu:\n","\n","```\n","python scripts/retriever/eval.py /path/to/format/A/dataset.txt --model /path/to/model\n","```\n","\n","## Document Reader\n","\n","Trình đọc tài liệu của DrQA là một mô hình hiểu máy mạng thần kinh tái phát nhiều lớp được đào tạo để trả lời câu hỏi khai thác. Đó là, mô hình cố gắng tìm câu trả lời cho bất kỳ câu hỏi nào dưới dạng khoảng văn bản trong một trong các tài liệu được trả về.\n","\n","\n","Trình đọc Tài liệu được lấy cảm hứng từ và được đào tạo chủ yếu về tập dữ liệu SQuAD. Nó cũng có thể được sử dụng độc lập trên các tác vụ giống SQuAD như vậy, trong đó ngữ cảnh cụ thể được cung cấp cùng với câu hỏi, câu trả lời được chứa trong ngữ cảnh.\n","\n","\n","Để xem cách đào tạo Trình đọc tài liệu trên SQuAD, hãy xem trình đọc README.\n","\n","\n","Để tương tác đặt câu hỏi về văn bản với một mô hình được đào tạo: \n","\n","```\n","python scripts/reader/interactive.py --model /path/to/model\n","```\n","\n","Một lần nữa, *model* ở đây là tùy chọn; một **model mặc định(có link)** được dùng nếu nó không được chỉ định.\n","\n","Để chạy mô hình dự đoán trên một bộ dữ liệu:\n","\n","```\n","python scripts/reader/predict.py /path/to/format/B/dataset.json --model /path/to/model\n","```\n","\n","## DrQA Pipeline\n","\n","Toàn bộ hệ thống được liên kết cùng nhau trong\n","    drqa.pipeline.DrQA\n","Để đặt câu hỏi tương tác sử dụng DrQA đầy đủ:\n","\n","```\n","python scripts/pipeline/interactive.py\n","```\n","\n","Các đối số tùy chọn:\n","\n","```\n","--reader-model    Path to trained Document Reader model.\n","--retriever-model Path to Document Retriever model (tfidf).\n","--doc-db          Path to Document DB.\n","--tokenizer      String option specifying tokenizer type to use (e.g. 'corenlp').\n","--candidate-file  List of candidates to restrict predictions to, one candidate per line.\n","--no-cuda         Use CPU only.\n","--gpu             Specify GPU device id to use.\n","```\n","\n","Để chạy dự đoán trên bộ dữ liệu:\n","\n","```\n","python scripts/pipeline/predict.py /path/to/format/A/dataset.txt\n","```\n","\n","Các đối số tùy chọn:\n","\n","```\n","--out-dir             Directory to write prediction file to (<dataset>-<model>-pipeline.preds).\n","--reader-model        Path to trained Document Reader model.\n","--retriever-model     Path to Document Retriever model (tfidf).\n","--doc-db              Path to Document DB.\n","--embedding-file      Expand dictionary to use all pretrained embeddings in this file (e.g. all glove vectors to minimize UNKs at test time).\n","--candidate-file      List of candidates to restrict predictions to, one candidate per line.\n","--n-docs              Number of docs to retrieve per query.\n","--top-n               Number of predictions to make per query.\n","--tokenizer           String option specifying tokenizer type to use (e.g. 'corenlp').\n","--no-cuda             Use CPU only.\n","--gpu                 Specify GPU device id to use.\n","--parallel            Use data parallel (split across GPU devices).\n","--num-workers         Number of CPU processes (for tokenizing, etc).\n","--batch-size          Document paragraph batching size (Reduce in case of GPU OOM).\n","--predict-batch-size  Question batching size (Reduce in case of CPU OOM).\n","```\n","\n","## Giám sát từ xa (DS)\n","\n","Hiệu suất của DrQA cải thiện đáng kể trong chế độ cài đặt đầy đủ khi được cung cấp dữ liệu giám sát từ xa từ các bộ dữ liệu bổ sung. Đưa ra các cặp câu hỏi-câu trả lời nhưng không có ngữ cảnh hỗ trợ, chúng ta có thể sử dụng phương pháp heuristics đối sánh chuỗi để tự động liên kết các đoạn văn với các ví dụ đào tạo này.\n","\n",">Question: What U.S. state’s motto is “Live free or Die”?\n",">\n",">Answer: New Hampshire\n",">\n",">DS Document: Live Free or Die\n","\n","Các tập lệnh\n","    scripts/distant\n","chứa mã để tạo và kiểm tra dữ liệu được giám sát từ xa như vậy. Chi tiết hơn có thể xem DS README.\n","\n","## Tokenizers\n","\n","Chúng tôi cung cấp một số tùy chọn tokenizer khác nhau cho sự thuận tiện. Mỗi cái có ưu nhược điểm dựa trên bao nhiêu thư viện được yêu cầu, chi phí để chạy, tốc độ và hiệu suất. Đối với các thử nghiệm được báo cáo của chúng tôi, chúng tôi đã sử dụng CoreNLP (nhưng tất cả các kết quả đều tương tự). \n","\n","Xem các danh sách tùy chọn trong class tokenizers"]},{"cell_type":"code","metadata":{"id":"IPlxSSnqpNo_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k90eTwQ-pQ31"},"source":["## Có thể tạo giao diện để dùng thông qua Github được viết sẵn."]}]}